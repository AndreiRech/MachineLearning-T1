{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee355e6b-d426-4e6b-ba3e-848f685e2402",
   "metadata": {},
   "source": [
    "# __kNN__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2052a7-4a23-449b-b5a5-b29e9fc0454a",
   "metadata": {},
   "source": [
    "***\n",
    "### _Prompts e Respostas_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57011d58-4bbd-442d-9584-3fb636a2a9d9",
   "metadata": {},
   "source": [
    "` Prompt 1 : Necessito que crie um algoritmo para o método de aprendizado supervisionado kNN na linguagem Python (Jupyter Notebook)`\n",
    "\n",
    "> Claro, vou te mostrar um exemplo simples de implementação do algoritmo kNN (k-nearest neighbors) em Python usando Jupyter Notebook. Antes de começarmos, é importante ter o NumPy instalado, pois vamos usá-lo para realizar operações matemáticas de forma eficiente. Você pode instalar o NumPy através do comando pip install numpy.\n",
    ">\n",
    "> Aqui está o código para a implementação do kNN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c0a441a-002d-4e9c-a1bb-eb31b8ed9544",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "class KNN:\n",
    "    def __init__(self, k=3):\n",
    "        self.k = k\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "\n",
    "    def predict(self, X):\n",
    "        y_pred = [self._predict(x) for x in X]\n",
    "        return np.array(y_pred)\n",
    "\n",
    "    def _predict(self, x):\n",
    "        # Calcula as distâncias entre x e todos os pontos de treinamento\n",
    "        distances = [np.sqrt(np.sum((x - x_train)**2)) for x_train in self.X_train]\n",
    "        # Ordena os índices dos pontos de treinamento por distância\n",
    "        k_indices = np.argsort(distances)[:self.k]\n",
    "        # Identifica as classes dos k vizinhos mais próximos\n",
    "        k_nearest_labels = [self.y_train[i] for i in k_indices]\n",
    "        # Retorna a classe mais comum entre os k vizinhos\n",
    "        most_common = np.bincount(k_nearest_labels).argmax()\n",
    "        return most_common"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7f5c9d-7035-4f5e-896e-8a3a1dbe52d9",
   "metadata": {},
   "source": [
    "***\n",
    "`Prompt 2 : Como posso utilizar um dataset neese conjunto, como o penguins?`\n",
    "\n",
    ">Para utilizar o conjunto de dados Penguins (pinguins) com o algoritmo kNN, primeiro você precisa carregar os dados e, em seguida, prepará-los para serem usados no modelo. O conjunto de dados Penguins é um conjunto popular que contém informações sobre pinguins, incluindo características como o comprimento e a profundidade do bico, o comprimento da asa, o peso corporal e a espécie de pinguim (Adélia, Papua ou Barbicha).\n",
    ">\n",
    ">Você pode usar a biblioteca seaborn para carregar o conjunto de dados Penguins e em seguida criar os conjuntos de treinamento e teste. Veja um exemplo de como fazer isso:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1b66818-55ef-43a4-aaf1-755a6286463e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia do modelo kNN: 1.00\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Carregando o conjunto de dados Penguins\n",
    "penguins = sns.load_dataset('penguins')\n",
    "\n",
    "# Removendo linhas com valores ausentes\n",
    "penguins.dropna(inplace=True)\n",
    "\n",
    "# Convertendo as espécies de pinguim para valores numéricos\n",
    "penguins['species'] = penguins['species'].map({'Adelie': 0, 'Chinstrap': 1, 'Gentoo': 2})\n",
    "\n",
    "# Separando as características (features) e o alvo (target)\n",
    "X = penguins[['bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g']]\n",
    "y = penguins['species']\n",
    "\n",
    "# Dividindo o conjunto de dados em treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Padronizando as características para terem média zero e variância unitária\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Criando e treinando o modelo kNN\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Fazendo previsões no conjunto de teste\n",
    "y_pred = knn.predict(X_test_scaled)\n",
    "\n",
    "# Calculando a acurácia do modelo\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Acurácia do modelo kNN: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a106111d-e529-4aaf-9349-ab8677f9a18b",
   "metadata": {},
   "source": [
    ">Neste exemplo:\n",
    ">\n",
    ">  1. Carregamos o conjunto de dados Penguins usando seaborn.\n",
    ">\n",
    ">  2. Removemos linhas com valores ausentes para garantir que o conjunto de dados esteja limpo.\n",
    ">\n",
    ">  3. Mapeamos as espécies de pinguim para valores numéricos para que possam ser usadas como alvo no modelo.\n",
    ">\n",
    ">  4. Dividimos os dados em conjuntos de treinamento e teste (80% treinamento, 20% teste).\n",
    ">\n",
    ">  5. Padronizamos as características (features) para terem média zero e variância unitária usando StandardScaler.\n",
    ">\n",
    ">  6. Criamos um modelo kNN com n_neighbors=3 e o treinamos com os dados de treinamento padronizados.\n",
    ">\n",
    ">  7. Fizemos previsões no conjunto de teste e calculamos a acurácia do modelo.\n",
    ">\n",
    ">Você pode ajustar os parâmetros do modelo kNN (como o número de vizinhos) e realizar outras etapas de pré-processamento conforme necessário para otimizar o desempenho do modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867769e6-d03a-4314-89e7-d00a10070d8e",
   "metadata": {},
   "source": [
    "***\n",
    "`Prompt 3 : Evite utilizar bibliotecas com implementações prontas (como o scikit-learn) e busque utilizar somente auxiliares para a computação vetorial (por exemplo, numpy)`\n",
    "\n",
    ">Entendi, vou criar um exemplo simples de implementação do kNN sem o uso de bibliotecas como scikit-learn, utilizando apenas o NumPy para operações matemáticas. Neste exemplo, usaremos o conjunto de dados Penguins e implementaremos o kNN manualmente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f689cb8-977a-4a3a-a3aa-aed8a1798fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia do modelo kNN: 1.00\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Carregando o conjunto de dados Penguins\n",
    "penguins = sns.load_dataset('penguins')\n",
    "\n",
    "# Removendo linhas com valores ausentes\n",
    "penguins.dropna(inplace=True)\n",
    "\n",
    "# Convertendo as espécies de pinguim para valores numéricos\n",
    "penguins['species'] = penguins['species'].map({'Adelie': 0, 'Chinstrap': 1, 'Gentoo': 2})\n",
    "\n",
    "# Separando as características (features) e o alvo (target)\n",
    "X = penguins[['bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g']].values\n",
    "y = penguins['species'].values\n",
    "\n",
    "# Função para calcular a distância euclidiana entre dois pontos\n",
    "def euclidean_distance(x1, x2):\n",
    "    return np.sqrt(np.sum((x1 - x2)**2))\n",
    "\n",
    "# Função para o algoritmo kNN\n",
    "def k_nearest_neighbors(X_train, y_train, X_test, k):\n",
    "    y_pred = []\n",
    "    for test_point in X_test:\n",
    "        distances = [euclidean_distance(train_point, test_point) for train_point in X_train]\n",
    "        nearest_indices = np.argsort(distances)[:k]\n",
    "        nearest_labels = y_train[nearest_indices]\n",
    "        most_common = np.bincount(nearest_labels).argmax()\n",
    "        y_pred.append(most_common)\n",
    "    return np.array(y_pred)\n",
    "\n",
    "# Dividindo o conjunto de dados em treinamento e teste\n",
    "np.random.seed(42)\n",
    "indices = np.random.permutation(len(X))\n",
    "split_ratio = 0.8\n",
    "split_index = int(len(X) * split_ratio)\n",
    "X_train, X_test = X[:split_index], X[split_index:]\n",
    "y_train, y_test = y[:split_index], y[split_index:]\n",
    "\n",
    "# Padronizando as características para terem média zero e variância unitária\n",
    "mean = X_train.mean(axis=0)\n",
    "std = X_train.std(axis=0)\n",
    "X_train_scaled = (X_train - mean) / std\n",
    "X_test_scaled = (X_test - mean) / std\n",
    "\n",
    "# Definindo o número de vizinhos para o kNN\n",
    "k = 3\n",
    "\n",
    "# Aplicando o algoritmo kNN\n",
    "y_pred = k_nearest_neighbors(X_train_scaled, y_train, X_test_scaled, k)\n",
    "\n",
    "# Calculando a acurácia do modelo\n",
    "accuracy = np.mean(y_pred == y_test)\n",
    "print(f'Acurácia do modelo kNN: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b94530-3059-4923-bde0-c08f091e34ad",
   "metadata": {},
   "source": [
    ">Neste código:\n",
    ">\n",
    ">  1. Carregamos o conjunto de dados Penguins e preparamos os dados como na versão anterior.\n",
    ">\n",
    ">  2. Implementamos a função euclidean_distance para calcular a distância euclidiana entre dois pontos.\n",
    ">\n",
    ">  3. Implementamos a função k_nearest_neighbors para o algoritmo kNN, que calcula as distâncias para os pontos de treinamento, encontra os k vizinhos mais próximos e faz a previsão da classe.\n",
    ">\n",
    ">  4. Dividimos o conjunto de dados em treinamento e teste manualmente.\n",
    ">\n",
    ">  5. Padronizamos as características manualmente para terem média zero e variância unitária.\n",
    ">   \n",
    ">  6. Definimos o número de vizinhos para o kNN como 3 e aplicamos o algoritmo.\n",
    ">      \n",
    ">  7. Calculamos a acurácia do modelo manualmente.\n",
    ">\n",
    ">Este exemplo demonstra como implementar o kNN sem o uso de bibliotecas prontas como scikit-learn, usando apenas o NumPy para operações matemáticas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3334b555-0cac-4dc7-b39a-4c9d49720848",
   "metadata": {},
   "source": [
    "***\n",
    "`Prompt 4 : A acurácia do modelo está resultando em 1.00, isso não quer dizer que há um overfit acontecendo?`\n",
    "\n",
    ">Uma acurácia de 1.00 (ou 100%) em um conjunto de teste pode indicar um possível problema de overfitting, especialmente se o modelo não foi ajustado adequadamente. Overfitting ocorre quando o modelo se ajusta tão bem aos dados de treinamento que ele não consegue generalizar bem para dados novos e não vistos, como os do conjunto de teste.\n",
    ">\n",
    ">Vamos revisar o código e considerar algumas abordagens para lidar com o possível overfitting:\n",
    ">\n",
    ">   1. Divisão de dados: A divisão dos dados em conjuntos de treinamento e teste deve ser feita de forma aleatória e representativa dos dados originais. Use o parâmetro random_state na função train_test_split para garantir que a divisão seja reproduzível.\n",
    ">      \n",
    ">   2. Padronização: A padronização das características é importante para muitos algoritmos de aprendizado de máquina, mas também pode impactar o desempenho do modelo. Verifique se a padronização está sendo aplicada corretamente e se não há vazamento de informações do conjunto de teste para o conjunto de treinamento.\n",
    ">\n",
    ">   3. Hiperparâmetros: No kNN, o número de vizinhos (k) é um hiperparâmetro crucial. Um valor muito baixo de k pode levar a overfitting, enquanto um valor muito alto pode levar a underfitting. Experimente diferentes valores de k para encontrar um equilíbrio.\n",
    ">\n",
    ">Vamos revisar o código anterior e adicionar algumas verificações e ajustes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24924cda-a90d-4f1b-9bc3-b3a4219f9370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia do modelo kNN: 0.99\n"
     ]
    }
   ],
   "source": [
    "# Dividindo o conjunto de dados em treinamento e teste\n",
    "np.random.seed(42)\n",
    "indices = np.random.permutation(len(X))\n",
    "split_ratio = 0.8\n",
    "split_index = int(len(X) * split_ratio)\n",
    "X_train, X_test = X[indices[:split_index]], X[indices[split_index:]]\n",
    "y_train, y_test = y[indices[:split_index]], y[indices[split_index:]]\n",
    "\n",
    "# Padronizando as características para terem média zero e variância unitária\n",
    "mean = X_train.mean(axis=0)\n",
    "std = X_train.std(axis=0)\n",
    "X_train_scaled = (X_train - mean) / std\n",
    "X_test_scaled = (X_test - mean) / std\n",
    "\n",
    "# Definindo o número de vizinhos para o kNN\n",
    "k = 5  # Valor ajustável\n",
    "\n",
    "# Aplicando o algoritmo kNN\n",
    "y_pred = k_nearest_neighbors(X_train_scaled, y_train, X_test_scaled, k)\n",
    "\n",
    "# Calculando a acurácia do modelo\n",
    "accuracy = np.mean(y_pred == y_test)\n",
    "print(f'Acurácia do modelo kNN: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3879ed-6881-440c-b1be-a79142f18926",
   "metadata": {},
   "source": [
    "> Neste código, ajustei o valor de k para 5, que é um valor comum usado no kNN. Além disso, garanti que a divisão dos dados em treinamento e teste seja feita de forma aleatória e usei um random_state fixo para tornar os resultados reproduzíveis.\n",
    ">\n",
    ">Se a acurácia ainda estiver muito alta, você pode tentar outros métodos de validação, como validação cruzada (k-fold cross-validation), para avaliar o desempenho do modelo de forma mais robusta e identificar possíveis problemas de overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13325abe-421f-466e-9743-8d41f1b609ff",
   "metadata": {},
   "source": [
    "***\n",
    "`Prompt 5 : Necessito que avalie os resultados com matriz de confusão, acurácia, recall, precisão e f1-score`\n",
    "\n",
    ">Para avaliar os resultados do modelo kNN de forma mais completa, podemos usar métricas como matriz de confusão, acurácia, recall, precisão e F1-score. Vou mostrar como calcular essas métricas usando apenas o NumPy e sem depender de bibliotecas externas como scikit-learn.\n",
    ">\n",
    ">Primeiro, vamos modificar o código anterior para incluir o cálculo dessas métricas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "798cdd2e-3d1d-42b3-8fcd-60bcf9913fe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusão:\n",
      "          Predito 0  Predito 1  Predito 2\n",
      "Classe 0         25          0          0\n",
      "Classe 1          1         15          0\n",
      "Classe 2          0          0         26\n",
      "\n",
      "Métricas Gerais:\n",
      "\n",
      "Acurácia: 0.99\n",
      "Média Recall: 0.9792\n",
      "Média Precisão: 0.9872\n",
      "Média F1-score: 0.9827\n",
      "\n",
      "Métricas por classe:\n",
      "\n",
      "Classe 0:\n",
      "Recall: 1.0000\n",
      "Precisão: 0.9615\n",
      "F1-score: 0.9804\n",
      "\n",
      "Classe 1:\n",
      "Recall: 0.9375\n",
      "Precisão: 1.0000\n",
      "F1-score: 0.9677\n",
      "\n",
      "Classe 2:\n",
      "Recall: 1.0000\n",
      "Precisão: 1.0000\n",
      "F1-score: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Aplicando o algoritmo kNN\n",
    "y_pred = k_nearest_neighbors(X_train_scaled, y_train, X_test_scaled, k)\n",
    "\n",
    "# Função para calcular a matriz de confusão\n",
    "def confusion_matrix(y_true, y_pred):\n",
    "    unique_classes = np.unique(np.concatenate((y_true, y_pred)))\n",
    "    num_classes = len(unique_classes)\n",
    "    matrix = np.zeros((num_classes, num_classes), dtype=int)\n",
    "    for i in range(len(y_true)):\n",
    "        matrix[y_true[i], y_pred[i]] += 1\n",
    "    return matrix\n",
    "\n",
    "# Função para calcular a acurácia\n",
    "def accuracy_score(y_true, y_pred):\n",
    "    correct = np.sum(y_true == y_pred)\n",
    "    total = len(y_true)\n",
    "    return correct / total\n",
    "\n",
    "# Função para calcular o recall, precisão e F1-score\n",
    "def calculate_metrics(conf_matrix):\n",
    "    tp = np.diag(conf_matrix)\n",
    "    fp = np.sum(conf_matrix, axis=0) - tp\n",
    "    fn = np.sum(conf_matrix, axis=1) - tp\n",
    "    \n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "    \n",
    "    return precision, recall, f1\n",
    "\n",
    "# Calculando a matriz de confusão\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "conf_matrix_df = pd.DataFrame(conf_matrix, index=['Classe 0', 'Classe 1', 'Classe 2'], columns=['Predito 0', 'Predito 1', 'Predito 2'])\n",
    "print('Matriz de Confusão:')\n",
    "print(conf_matrix_df)\n",
    "\n",
    "# Calculando e exibindo as métricas\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision, recall, f1 = calculate_metrics(conf_matrix)\n",
    "\n",
    "# Calculando as médias das métricas\n",
    "mean_recall = np.mean(recall)\n",
    "mean_precision = np.mean(precision)\n",
    "mean_f1 = np.mean(f1)\n",
    "\n",
    "# Exibindo as métricas gerais\n",
    "print('\\nMétricas Gerais:')\n",
    "print(f'\\nAcurácia: {accuracy:.2f}')\n",
    "print(f'Média Recall: {mean_recall:.4f}')\n",
    "print(f'Média Precisão: {mean_precision:.4f}')\n",
    "print(f'Média F1-score: {mean_f1:.4f}')\n",
    "\n",
    "print('\\nMétricas por classe:')\n",
    "unique_classes = np.unique(np.concatenate((y_test, y_pred)))\n",
    "for i in range(len(unique_classes)):\n",
    "    print(f'\\nClasse {i}:')\n",
    "    print(f'Recall: {recall[i]:.4f}')\n",
    "    print(f'Precisão: {precision[i]:.4f}')\n",
    "    print(f'F1-score: {f1[i]:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d8b415-defe-4c0e-8251-0b9a1e827649",
   "metadata": {},
   "source": [
    ">Neste código:\n",
    ">\n",
    ">   1. Adicionamos a função confusion_matrix para calcular a matriz de confusão.\n",
    ">\n",
    ">   2. Implementamos funções para calcular a acurácia, recall, precisão e F1-score com base na matriz de confusão.\n",
    ">\n",
    ">   3. Calculamos as métricas para o modelo kNN treinado e exibimos os resultados.\n",
    ">\n",
    ">Execute este código após a etapa de treinamento e teste do kNN para obter as métricas de avaliação completas. Isso permitirá uma análise mais aprofundada do desempenho do modelo em relação às diferentes classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f8ffcc-6f34-4d3c-bedc-81e99ae253c6",
   "metadata": {},
   "source": [
    "***\n",
    "### _Aplicando o Código_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96735e06-207d-479f-a532-8de2752ebf88",
   "metadata": {},
   "source": [
    "Note que a aplicação do código é somente a __junção de todos os prompts resultantes__. \n",
    "\n",
    "Caso deseje testar com __outros valores__ [ _Ex: valor de k | % de divisão de dados teste_ ] \n",
    "é necessário alterar os seus valores __dentro do código__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b44e208a-81f0-4175-a06d-1d08e1443053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusão:\n",
      "          Predito 0  Predito 1  Predito 2\n",
      "Classe 0         25          0          0\n",
      "Classe 1          1         15          0\n",
      "Classe 2          0          0         26\n",
      "\n",
      "Métricas Gerais:\n",
      "\n",
      "Acurácia: 0.99\n",
      "Média Recall: 0.9792\n",
      "Média Precisão: 0.9872\n",
      "Média F1-score: 0.9827\n",
      "\n",
      "Métricas por classe:\n",
      "\n",
      "Classe 0:\n",
      "Recall: 1.0000\n",
      "Precisão: 0.9615\n",
      "F1-score: 0.9804\n",
      "\n",
      "Classe 1:\n",
      "Recall: 0.9375\n",
      "Precisão: 1.0000\n",
      "F1-score: 0.9677\n",
      "\n",
      "Classe 2:\n",
      "Recall: 1.0000\n",
      "Precisão: 1.0000\n",
      "F1-score: 1.0000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Definição da classe principal\n",
    "class KNN:\n",
    "    def __init__(self, k=3):\n",
    "        self.k = k\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "\n",
    "    def predict(self, X):\n",
    "        y_pred = [self._predict(x) for x in X]\n",
    "        return np.array(y_pred)\n",
    "\n",
    "    def _predict(self, x):\n",
    "        distances = [np.sqrt(np.sum((x - x_train)**2)) for x_train in self.X_train]\n",
    "        k_indices = np.argsort(distances)[:self.k]\n",
    "        k_nearest_labels = [self.y_train[i] for i in k_indices]\n",
    "        most_common = np.bincount(k_nearest_labels).argmax()\n",
    "        return most_common\n",
    "\n",
    "# Limpeza dos dados, treino e testes\n",
    "penguins = sns.load_dataset('penguins')\n",
    "\n",
    "penguins.dropna(inplace=True)\n",
    "\n",
    "penguins['species'] = penguins['species'].map({'Adelie': 0, 'Chinstrap': 1, 'Gentoo': 2})\n",
    "\n",
    "X = penguins[['bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g']].values\n",
    "y = penguins['species'].values\n",
    "\n",
    "def euclidean_distance(x1, x2):\n",
    "    return np.sqrt(np.sum((x1 - x2)**2))\n",
    "\n",
    "def k_nearest_neighbors(X_train, y_train, X_test, k):\n",
    "    y_pred = []\n",
    "    for test_point in X_test:\n",
    "        distances = [euclidean_distance(train_point, test_point) for train_point in X_train]\n",
    "        nearest_indices = np.argsort(distances)[:k]\n",
    "        nearest_labels = y_train[nearest_indices]\n",
    "        most_common = np.bincount(nearest_labels).argmax()\n",
    "        y_pred.append(most_common)\n",
    "    return np.array(y_pred)\n",
    "\n",
    "# Padronização\n",
    "np.random.seed(42)\n",
    "indices = np.random.permutation(len(X))\n",
    "split_ratio = 0.8\n",
    "split_index = int(len(X) * split_ratio)\n",
    "X_train, X_test = X[indices[:split_index]], X[indices[split_index:]]\n",
    "y_train, y_test = y[indices[:split_index]], y[indices[split_index:]]\n",
    "\n",
    "mean = X_train.mean(axis=0)\n",
    "std = X_train.std(axis=0)\n",
    "X_train_scaled = (X_train - mean) / std\n",
    "X_test_scaled = (X_test - mean) / std\n",
    "\n",
    "# Aplicando\n",
    "k = 5\n",
    "\n",
    "y_pred = k_nearest_neighbors(X_train_scaled, y_train, X_test_scaled, k)\n",
    "\n",
    "# Funções de estatísticas\n",
    "def confusion_matrix(y_true, y_pred):\n",
    "    unique_classes = np.unique(np.concatenate((y_true, y_pred)))\n",
    "    num_classes = len(unique_classes)\n",
    "    matrix = np.zeros((num_classes, num_classes), dtype=int)\n",
    "    for i in range(len(y_true)):\n",
    "        matrix[y_true[i], y_pred[i]] += 1\n",
    "    return matrix\n",
    "\n",
    "def accuracy_score(y_true, y_pred):\n",
    "    correct = np.sum(y_true == y_pred)\n",
    "    total = len(y_true)\n",
    "    return correct / total\n",
    "\n",
    "def calculate_metrics(conf_matrix):\n",
    "    tp = np.diag(conf_matrix)\n",
    "    fp = np.sum(conf_matrix, axis=0) - tp\n",
    "    fn = np.sum(conf_matrix, axis=1) - tp\n",
    "    \n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "    \n",
    "    return precision, recall, f1\n",
    "\n",
    "# Printando o resultado\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "conf_matrix_df = pd.DataFrame(conf_matrix, index=['Classe 0', 'Classe 1', 'Classe 2'], columns=['Predito 0', 'Predito 1', 'Predito 2'])\n",
    "print('Matriz de Confusão:')\n",
    "print(conf_matrix_df)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision, recall, f1 = calculate_metrics(conf_matrix)\n",
    "\n",
    "mean_recall = np.mean(recall)\n",
    "mean_precision = np.mean(precision)\n",
    "mean_f1 = np.mean(f1)\n",
    "\n",
    "print('\\nMétricas Gerais:')\n",
    "print(f'\\nAcurácia: {accuracy:.2f}')\n",
    "print(f'Média Recall: {mean_recall:.4f}')\n",
    "print(f'Média Precisão: {mean_precision:.4f}')\n",
    "print(f'Média F1-score: {mean_f1:.4f}')\n",
    "\n",
    "print('\\nMétricas por classe:')\n",
    "unique_classes = np.unique(np.concatenate((y_test, y_pred)))\n",
    "for i in range(len(unique_classes)):\n",
    "    print(f'\\nClasse {i}:')\n",
    "    print(f'Recall: {recall[i]:.4f}')\n",
    "    print(f'Precisão: {precision[i]:.4f}')\n",
    "    print(f'F1-score: {f1[i]:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9435cc-9565-4197-ba6f-1512ab49674f",
   "metadata": {},
   "source": [
    "***\n",
    "### _Análise e Considerações_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
