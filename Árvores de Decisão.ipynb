{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce81486c-2b33-4624-a801-494814266106",
   "metadata": {},
   "source": [
    "# __ÁRVORES DE DECISÃO__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0bada04-0580-4174-9fb3-37fa1a4721b5",
   "metadata": {},
   "source": [
    "***\n",
    "## _Prompts e Respostas_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5f7bbf",
   "metadata": {},
   "source": [
    "` Prompt 1: Necessito que crie um algoritmo sem o uso de bibliotecas como o 'scikit-learn' para o método de aprendizado supervisionado Árvores de Decisão que lide com valores numéricos e categóricos utilizando Gini para verificar a pureza dos nós na linguagem Python (Jupyter Notebook)`\n",
    "\n",
    ">Claro, vou lhe fornecer um exemplo simples de como implementar um algoritmo de Árvore de Decisão utilizando o critério de Gini para medir a pureza dos nós, sem depender da biblioteca scikit-learn. Aqui está um exemplo básico em Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "fc305d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, feature_index=None, threshold=None, left=None, right=None, value=None):\n",
    "        self.feature_index = feature_index  # Índice do recurso usado para dividir os dados\n",
    "        self.threshold = threshold  # Valor de divisão\n",
    "        self.left = left  # Subárvore à esquerda\n",
    "        self.right = right  # Subárvore à direita\n",
    "        self.value = value  # Valor da classe para folhas (somente se for uma folha)\n",
    "\n",
    "class DecisionTreeClassifier:\n",
    "    def __init__(self, max_depth=None):\n",
    "        self.max_depth = max_depth\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.num_classes = len(set(y))\n",
    "        self.num_features = X.shape[1]\n",
    "        self.tree = self._grow_tree(X, y)\n",
    "\n",
    "    def _gini(self, y):\n",
    "        classes = set(y)\n",
    "        n_instances = len(y)\n",
    "        gini = 1.0\n",
    "        for cls in classes:\n",
    "            proportion = np.sum(y == cls) / n_instances\n",
    "            gini -= proportion ** 2\n",
    "        return gini\n",
    "\n",
    "    def _best_split(self, X, y):\n",
    "        best_gini = float('inf')\n",
    "        best_criteria = None  # Critérios para divisão: (feature_index, threshold)\n",
    "        \n",
    "        for feature_index in range(self.num_features):\n",
    "            thresholds = np.unique(X[:, feature_index])\n",
    "            for threshold in thresholds:\n",
    "                left_indices = np.where(X[:, feature_index] <= threshold)[0]\n",
    "                right_indices = np.where(X[:, feature_index] > threshold)[0]\n",
    "                \n",
    "                if len(left_indices) == 0 or len(right_indices) == 0:\n",
    "                    continue\n",
    "                \n",
    "                gini = self._gini_split(y[left_indices], y[right_indices])\n",
    "                \n",
    "                if gini < best_gini:\n",
    "                    best_gini = gini\n",
    "                    best_criteria = (feature_index, threshold)\n",
    "        \n",
    "        return best_criteria\n",
    "\n",
    "    def _gini_split(self, left_y, right_y):\n",
    "        p_left = len(left_y) / (len(left_y) + len(right_y))\n",
    "        gini_left = self._gini(left_y)\n",
    "        gini_right = self._gini(right_y)\n",
    "        gini = p_left * gini_left + (1 - p_left) * gini_right\n",
    "        return gini\n",
    "\n",
    "    def _grow_tree(self, X, y, depth=0):\n",
    "        num_samples_per_class = [np.sum(y == i) for i in range(self.num_classes)]\n",
    "        predicted_class = np.argmax(num_samples_per_class)\n",
    "        node = Node(value=predicted_class)\n",
    "        \n",
    "        if depth < self.max_depth:\n",
    "            criteria = self._best_split(X, y)\n",
    "            if criteria:\n",
    "                feature_index, threshold = criteria\n",
    "                left_indices = np.where(X[:, feature_index] <= threshold)[0]\n",
    "                right_indices = np.where(X[:, feature_index] > threshold)[0]\n",
    "                left_subtree = self._grow_tree(X[left_indices], y[left_indices], depth + 1)\n",
    "                right_subtree = self._grow_tree(X[right_indices], y[right_indices], depth + 1)\n",
    "                node = Node(feature_index=feature_index, threshold=threshold, left=left_subtree, right=right_subtree)\n",
    "        return node\n",
    "\n",
    "    def predict(self, X):\n",
    "        return [self._predict_tree(x, self.tree) for x in X]\n",
    "\n",
    "    def _predict_tree(self, x, tree):\n",
    "        if tree.value is not None:\n",
    "            return tree.value\n",
    "        feature_value = x[tree.feature_index]\n",
    "        if feature_value <= tree.threshold:\n",
    "            return self._predict_tree(x, tree.left)\n",
    "        else:\n",
    "            return self._predict_tree(x, tree.right)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a4da04",
   "metadata": {},
   "source": [
    "`Prompt 2: Obrigado! Agora quero que você utilize o dataset \"Penguins\" para testar esse algoritmo, sem o uso de bibliotecas como o skitlearn`\n",
    "\n",
    ">Claro! Vou utilizar o conjunto de dados \"Penguins\" para testar o algoritmo de Árvore de Decisão que acabamos de implementar. Primeiro, vamos carregar e visualizar os dados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "68e7a009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  species     island  bill_length_mm  bill_depth_mm  flipper_length_mm  \\\n",
      "0  Adelie  Torgersen            39.1           18.7                181   \n",
      "1  Adelie  Torgersen            39.5           17.4                186   \n",
      "2  Adelie  Torgersen            40.3           18.0                195   \n",
      "3  Adelie  Torgersen            36.7           19.3                193   \n",
      "4  Adelie  Torgersen            39.3           20.6                190   \n",
      "\n",
      "   body_mass_g     sex  \n",
      "0         3750    male  \n",
      "1         3800  female  \n",
      "2         3250  female  \n",
      "3         3450  female  \n",
      "4         3650    male  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Carregar o conjunto de dados penguins\n",
    "penguins_data = pd.read_csv(\"https://raw.githubusercontent.com/dataprofessor/data/master/penguins_cleaned.csv\")\n",
    "\n",
    "# Visualizar as primeiras linhas do conjunto de dados\n",
    "print(penguins_data.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba10af57",
   "metadata": {},
   "source": [
    ">Agora, vamos pré-processar os dados para que possam ser usados no nosso algoritmo de Árvore de Decisão:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "94366ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Remover linhas com valores nulos\n",
    "penguins_data.dropna(inplace=True)\n",
    "\n",
    "# Converter variáveis categóricas em numéricas usando one-hot encoding manualmente\n",
    "penguins_data = pd.concat([penguins_data, pd.get_dummies(penguins_data['species'], prefix='species')], axis=1)\n",
    "penguins_data = pd.concat([penguins_data, pd.get_dummies(penguins_data['island'], prefix='island')], axis=1)\n",
    "penguins_data = pd.concat([penguins_data, pd.get_dummies(penguins_data['sex'], prefix='sex')], axis=1)\n",
    "\n",
    "# Remover as colunas originais categóricas\n",
    "penguins_data.drop(['species', 'island', 'sex'], axis=1, inplace=True)\n",
    "\n",
    "# Separar os dados em features (X) e target (y)\n",
    "X = penguins_data.drop('species_Chinstrap', axis=1).values\n",
    "y = penguins_data['species_Chinstrap'].values\n",
    "\n",
    "# Dividir os dados manualmente em conjunto de treinamento e conjunto de teste\n",
    "def manual_train_test_split(X, y, test_size=0.2, random_state=None):\n",
    "    if random_state:\n",
    "        np.random.seed(random_state)\n",
    "        \n",
    "    num_samples = len(X)\n",
    "    indices = np.random.permutation(num_samples)\n",
    "    test_size = int(test_size * num_samples)\n",
    "    \n",
    "    X_train = X[indices[:-test_size]]\n",
    "    X_test = X[indices[-test_size:]]\n",
    "    y_train = y[indices[:-test_size]]\n",
    "    y_test = y[indices[-test_size:]]\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "X_train, X_test, y_train, y_test = manual_train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489e2f48",
   "metadata": {},
   "source": [
    "`Prompt 4: Agora como posso fazer para apresentar as métricas?`\n",
    ">Para apresentar as métricas do modelo, como a acurácia, você pode implementar essas métricas manualmente. Aqui está um exemplo de como você pode calcular a acurácia manualmente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ed8eab04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia do modelo: 1.0\n"
     ]
    }
   ],
   "source": [
    "def accuracy_score(y_true, y_pred):\n",
    "    correct = 0\n",
    "    total = len(y_true)\n",
    "    for true_label, pred_label in zip(y_true, y_pred):\n",
    "        if true_label == pred_label:\n",
    "            correct += 1\n",
    "    return correct / total\n",
    "\n",
    "# Fazer previsões\n",
    "predictions = tree.predict(X_test)\n",
    "\n",
    "# Calcular a acurácia\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Acurácia do modelo:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3a700b",
   "metadata": {},
   "source": [
    "` Prompt 5: A acurácia do modelo está resultando em 1, isso não significa overfitting? como eu resolvo?`\n",
    "\n",
    ">Uma acurácia de 1.0 (ou 100%) nos dados de teste pode indicar overfitting, especialmente se o modelo não estiver sendo avaliado em um conjunto de validação. Overfitting ocorre quando o modelo se ajusta demais aos dados de treinamento e não generaliza bem para dados novos.\n",
    "\n",
    ">Para resolver o overfitting, você pode tentar algumas abordagens:\n",
    "\n",
    ">Reduzir a complexidade do modelo: Reduza a profundidade da árvore de decisão ou aplique técnicas de poda para simplificar a estrutura da árvore.\n",
    "\n",
    ">Regularização: Introduza parâmetros de regularização, como limitar o número máximo de folhas em uma árvore ou introduzir penalidades nos pesos dos nós.\n",
    "\n",
    ">Cross-validation: Use técnicas de validação cruzada para avaliar o desempenho do modelo em diferentes subconjuntos dos dados e encontrar hiperparâmetros que generalizam bem.\n",
    "\n",
    ">Aumentar o tamanho do conjunto de teste: Se o tamanho do conjunto de teste for pequeno, é possível que a acurácia seja superestimada. Aumente o tamanho do conjunto de teste para uma estimativa mais confiável do desempenho do modelo.\n",
    "\n",
    ">Vamos implementar a validação cruzada para avaliar melhor o desempenho do modelo e evitar o overfitting. Aqui está um exemplo de como você pode fazer isso:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "18292b60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia média da validação cruzada: 1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Definir uma função para dividir os dados em K folds\n",
    "def k_fold_split(X, y, num_folds=5, random_state=None):\n",
    "    if random_state:\n",
    "        np.random.seed(random_state)\n",
    "    \n",
    "    num_samples = len(X)\n",
    "    fold_size = num_samples // num_folds\n",
    "    indices = np.random.permutation(num_samples)\n",
    "    \n",
    "    for i in range(num_folds):\n",
    "        start = i * fold_size\n",
    "        end = (i + 1) * fold_size if i < num_folds - 1 else num_samples\n",
    "        \n",
    "        test_indices = indices[start:end]\n",
    "        train_indices = np.concatenate((indices[:start], indices[end:]))\n",
    "        \n",
    "        yield X[train_indices], X[test_indices], y[train_indices], y[test_indices]\n",
    "\n",
    "# Definir uma função para calcular a acurácia\n",
    "def accuracy_score(y_true, y_pred):\n",
    "    correct = np.sum(y_true == y_pred)\n",
    "    total = len(y_true)\n",
    "    return correct / total\n",
    "\n",
    "# Realizar validação cruzada\n",
    "num_folds = 5\n",
    "accuracies = []\n",
    "\n",
    "for X_train_fold, X_test_fold, y_train_fold, y_test_fold in k_fold_split(X_train, y_train, num_folds=num_folds, random_state=42):\n",
    "    # Treinar o modelo em um fold\n",
    "    tree_fold = DecisionTreeClassifier(max_depth=3)\n",
    "    tree_fold.fit(X_train_fold, y_train_fold)\n",
    "    \n",
    "    # Fazer previsões no conjunto de teste do fold atual\n",
    "    predictions_fold = tree_fold.predict(X_test_fold)\n",
    "    \n",
    "    # Calcular a acurácia para este fold\n",
    "    accuracy_fold = accuracy_score(y_test_fold, predictions_fold)\n",
    "    accuracies.append(accuracy_fold)\n",
    "\n",
    "# Calcular a acurácia média da validação cruzada\n",
    "mean_accuracy = np.mean(accuracies)\n",
    "print(\"Acurácia média da validação cruzada:\", mean_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef27d0a",
   "metadata": {},
   "source": [
    ">Essencialmente, esta implementação divide os dados em num_folds partes, treina o modelo em cada parte (fold) e avalia o desempenho do modelo em um conjunto de teste separado para cada fold. Finalmente, calcula a média das acurácias obtidas em cada fold para obter a acurácia média da validação cruzada."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0bfeb42-1db6-49a5-a7ee-6e0aedfaa61a",
   "metadata": {},
   "source": [
    "***\n",
    "## _Aplicando o Código_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0f7e17-ec56-456e-8944-6ac8827ea44f",
   "metadata": {},
   "source": [
    "***\n",
    "## _Análise e Considerações_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce113802-2897-4c5b-ba21-946a24a8f050",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
