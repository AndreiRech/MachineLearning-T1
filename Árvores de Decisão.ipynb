{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce81486c-2b33-4624-a801-494814266106",
   "metadata": {},
   "source": [
    "# __ÁRVORES DE DECISÃO__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0bada04-0580-4174-9fb3-37fa1a4721b5",
   "metadata": {},
   "source": [
    "***\n",
    "## _Prompts e Respostas_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5f7bbf",
   "metadata": {},
   "source": [
    "` Prompt 1: Necessito que crie um algoritmo sem o uso de bibliotecas como o 'scikit-learn' para o método de aprendizado supervisionado Árvores de Decisão que lide com valores numéricos e categóricos utilizando Gini para verificar a pureza dos nós na linguagem Python (Jupyter Notebook)`\n",
    "\n",
    ">Claro, vou lhe fornecer um exemplo simples de como implementar um algoritmo de Árvore de Decisão utilizando o critério de Gini para medir a pureza dos nós, sem depender da biblioteca scikit-learn. Aqui está um exemplo básico em Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fc305d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, feature_index=None, threshold=None, left=None, right=None, value=None):\n",
    "        self.feature_index = feature_index  # Índice do recurso usado para dividir os dados\n",
    "        self.threshold = threshold  # Valor de divisão\n",
    "        self.left = left  # Subárvore à esquerda\n",
    "        self.right = right  # Subárvore à direita\n",
    "        self.value = value  # Valor da classe para folhas (somente se for uma folha)\n",
    "\n",
    "class DecisionTreeClassifier:\n",
    "    def __init__(self, max_depth=None):\n",
    "        self.max_depth = max_depth\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.num_classes = len(set(y))\n",
    "        self.num_features = X.shape[1]\n",
    "        self.tree = self._grow_tree(X, y)\n",
    "\n",
    "    def _gini(self, y):\n",
    "        classes = set(y)\n",
    "        n_instances = len(y)\n",
    "        gini = 1.0\n",
    "        for cls in classes:\n",
    "            proportion = np.sum(y == cls) / n_instances\n",
    "            gini -= proportion ** 2\n",
    "        return gini\n",
    "\n",
    "    def _best_split(self, X, y):\n",
    "        best_gini = float('inf')\n",
    "        best_criteria = None  # Critérios para divisão: (feature_index, threshold)\n",
    "        \n",
    "        for feature_index in range(self.num_features):\n",
    "            thresholds = np.unique(X[:, feature_index])\n",
    "            for threshold in thresholds:\n",
    "                left_indices = np.where(X[:, feature_index] <= threshold)[0]\n",
    "                right_indices = np.where(X[:, feature_index] > threshold)[0]\n",
    "                \n",
    "                if len(left_indices) == 0 or len(right_indices) == 0:\n",
    "                    continue\n",
    "                \n",
    "                gini = self._gini_split(y[left_indices], y[right_indices])\n",
    "                \n",
    "                if gini < best_gini:\n",
    "                    best_gini = gini\n",
    "                    best_criteria = (feature_index, threshold)\n",
    "        \n",
    "        return best_criteria\n",
    "\n",
    "    def _gini_split(self, left_y, right_y):\n",
    "        p_left = len(left_y) / (len(left_y) + len(right_y))\n",
    "        gini_left = self._gini(left_y)\n",
    "        gini_right = self._gini(right_y)\n",
    "        gini = p_left * gini_left + (1 - p_left) * gini_right\n",
    "        return gini\n",
    "\n",
    "    def _grow_tree(self, X, y, depth=0):\n",
    "        num_samples_per_class = [np.sum(y == i) for i in range(self.num_classes)]\n",
    "        predicted_class = np.argmax(num_samples_per_class)\n",
    "        node = Node(value=predicted_class)\n",
    "        \n",
    "        if depth < self.max_depth:\n",
    "            criteria = self._best_split(X, y)\n",
    "            if criteria:\n",
    "                feature_index, threshold = criteria\n",
    "                left_indices = np.where(X[:, feature_index] <= threshold)[0]\n",
    "                right_indices = np.where(X[:, feature_index] > threshold)[0]\n",
    "                left_subtree = self._grow_tree(X[left_indices], y[left_indices], depth + 1)\n",
    "                right_subtree = self._grow_tree(X[right_indices], y[right_indices], depth + 1)\n",
    "                node = Node(feature_index=feature_index, threshold=threshold, left=left_subtree, right=right_subtree)\n",
    "        return node\n",
    "\n",
    "    def predict(self, X):\n",
    "        return [self._predict_tree(x, self.tree) for x in X]\n",
    "\n",
    "    def _predict_tree(self, x, tree):\n",
    "        if tree.value is not None:\n",
    "            return tree.value\n",
    "        feature_value = x[tree.feature_index]\n",
    "        if feature_value <= tree.threshold:\n",
    "            return self._predict_tree(x, tree.left)\n",
    "        else:\n",
    "            return self._predict_tree(x, tree.right)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a4da04",
   "metadata": {},
   "source": [
    "`Prompt 2: Obrigado! Agora quero que você utilize o dataset \"Penguins\" para testar esse algoritmo, sem o uso de bibliotecas como o skitlearn`\n",
    "\n",
    ">Claro! Vou utilizar o conjunto de dados \"Penguins\" para testar o algoritmo de Árvore de Decisão que acabamos de implementar. Primeiro, vamos carregar e visualizar os dados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "68e7a009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  species     island  bill_length_mm  bill_depth_mm  flipper_length_mm  \\\n",
      "0  Adelie  Torgersen            39.1           18.7                181   \n",
      "1  Adelie  Torgersen            39.5           17.4                186   \n",
      "2  Adelie  Torgersen            40.3           18.0                195   \n",
      "3  Adelie  Torgersen            36.7           19.3                193   \n",
      "4  Adelie  Torgersen            39.3           20.6                190   \n",
      "\n",
      "   body_mass_g     sex  \n",
      "0         3750    male  \n",
      "1         3800  female  \n",
      "2         3250  female  \n",
      "3         3450  female  \n",
      "4         3650    male  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Carregar o conjunto de dados penguins\n",
    "penguins_data = pd.read_csv(\"https://raw.githubusercontent.com/dataprofessor/data/master/penguins_cleaned.csv\")\n",
    "\n",
    "# Visualizar as primeiras linhas do conjunto de dados\n",
    "print(penguins_data.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba10af57",
   "metadata": {},
   "source": [
    ">Agora, vamos pré-processar os dados para que possam ser usados no nosso algoritmo de Árvore de Decisão:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94366ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Remover linhas com valores nulos\n",
    "penguins_data.dropna(inplace=True)\n",
    "\n",
    "# Converter variáveis categóricas em numéricas usando one-hot encoding manualmente\n",
    "penguins_data = pd.concat([penguins_data, pd.get_dummies(penguins_data['species'], prefix='species')], axis=1)\n",
    "penguins_data = pd.concat([penguins_data, pd.get_dummies(penguins_data['island'], prefix='island')], axis=1)\n",
    "penguins_data = pd.concat([penguins_data, pd.get_dummies(penguins_data['sex'], prefix='sex')], axis=1)\n",
    "\n",
    "# Remover as colunas originais categóricas\n",
    "penguins_data.drop(['species', 'island', 'sex'], axis=1, inplace=True)\n",
    "\n",
    "# Separar os dados em features (X) e target (y)\n",
    "X = penguins_data.drop('species_Chinstrap', axis=1).values\n",
    "y = penguins_data['species_Chinstrap'].values\n",
    "\n",
    "# Dividir os dados manualmente em conjunto de treinamento e conjunto de teste\n",
    "def manual_train_test_split(X, y, test_size=0.2, random_state=None):\n",
    "    if random_state:\n",
    "        np.random.seed(random_state)\n",
    "        \n",
    "    num_samples = len(X)\n",
    "    indices = np.random.permutation(num_samples)\n",
    "    test_size = int(test_size * num_samples)\n",
    "    \n",
    "    X_train = X[indices[:-test_size]]\n",
    "    X_test = X[indices[-test_size:]]\n",
    "    y_train = y[indices[:-test_size]]\n",
    "    y_test = y[indices[-test_size:]]\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "X_train, X_test, y_train, y_test = manual_train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489e2f48",
   "metadata": {},
   "source": [
    "`Prompt 4: Agora como posso fazer para apresentar as métricas?`\n",
    ">Para apresentar as métricas do modelo, como a acurácia, você pode implementar essas métricas manualmente. Aqui está um exemplo de como você pode calcular a acurácia manualmente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ed8eab04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia do modelo: 1.0\n"
     ]
    }
   ],
   "source": [
    "def accuracy_score(y_true, y_pred):\n",
    "    correct = 0\n",
    "    total = len(y_true)\n",
    "    for true_label, pred_label in zip(y_true, y_pred):\n",
    "        if true_label == pred_label:\n",
    "            correct += 1\n",
    "    return correct / total\n",
    "# Criar uma instância do DecisionTreeClassifier com max_depth definido\n",
    "tree_classifier = DecisionTreeClassifier(max_depth=3)\n",
    "\n",
    "# Treinar o modelo com os dados de treinamento\n",
    "tree_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Fazer previsões nos dados de teste\n",
    "predictions = tree_classifier.predict(X_test)\n",
    "\n",
    "# Calcular a acurácia usando a função accuracy_score\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Acurácia do modelo:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c22c2b0",
   "metadata": {},
   "source": [
    ">Você também pode calcular outras métricas, como precisão, recall e F1-score, se desejar. Essas métricas exigirão um pouco mais de código, mas seguem a mesma ideia básica de comparar as previsões do modelo com os valores reais e calcular a proporção de previsões corretas em relação ao total."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3a700b",
   "metadata": {},
   "source": [
    "` Prompt 5: A acurácia do modelo está resultando em 1, isso não significa overfitting? como eu resolvo?`\n",
    "\n",
    ">Uma acurácia de 1.0 (ou 100%) nos dados de teste pode indicar overfitting, especialmente se o modelo não estiver sendo avaliado em um conjunto de validação. Overfitting ocorre quando o modelo se ajusta demais aos dados de treinamento e não generaliza bem para dados novos.\n",
    ">\n",
    ">Para resolver o overfitting, você pode tentar algumas abordagens:\n",
    ">\n",
    ">Reduzir a complexidade do modelo: Reduza a profundidade da árvore de decisão ou aplique técnicas de poda para simplificar a estrutura da árvore.\n",
    ">\n",
    ">Regularização: Introduza parâmetros de regularização, como limitar o número máximo de folhas em uma árvore ou introduzir penalidades nos pesos dos nós.\n",
    ">\n",
    ">Cross-validation: Use técnicas de validação cruzada para avaliar o desempenho do modelo em diferentes subconjuntos dos dados e encontrar hiperparâmetros que generalizam bem.\n",
    ">\n",
    ">Aumentar o tamanho do conjunto de teste: Se o tamanho do conjunto de teste for pequeno, é possível que a acurácia seja superestimada. Aumente o tamanho do conjunto de teste para uma estimativa mais confiável do desempenho do modelo.\n",
    ">\n",
    ">Vamos implementar a validação cruzada para avaliar melhor o desempenho do modelo e evitar o overfitting. Aqui está um exemplo de como você pode fazer isso:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "18292b60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia média da validação cruzada: 1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Definir uma função para dividir os dados em K folds\n",
    "def k_fold_split(X, y, num_folds=5, random_state=None):\n",
    "    if random_state:\n",
    "        np.random.seed(random_state)\n",
    "    \n",
    "    num_samples = len(X)\n",
    "    fold_size = num_samples // num_folds\n",
    "    indices = np.random.permutation(num_samples)\n",
    "    \n",
    "    for i in range(num_folds):\n",
    "        start = i * fold_size\n",
    "        end = (i + 1) * fold_size if i < num_folds - 1 else num_samples\n",
    "        \n",
    "        test_indices = indices[start:end]\n",
    "        train_indices = np.concatenate((indices[:start], indices[end:]))\n",
    "        \n",
    "        yield X[train_indices], X[test_indices], y[train_indices], y[test_indices]\n",
    "\n",
    "# Definir uma função para calcular a acurácia\n",
    "def accuracy_score(y_true, y_pred):\n",
    "    correct = np.sum(y_true == y_pred)\n",
    "    total = len(y_true)\n",
    "    return correct / total\n",
    "\n",
    "# Realizar validação cruzada\n",
    "num_folds = 5\n",
    "accuracies = []\n",
    "\n",
    "for X_train_fold, X_test_fold, y_train_fold, y_test_fold in k_fold_split(X_train, y_train, num_folds=num_folds, random_state=42):\n",
    "    # Treinar o modelo em um fold\n",
    "    tree_fold = DecisionTreeClassifier(max_depth=3)\n",
    "    tree_fold.fit(X_train_fold, y_train_fold)\n",
    "    \n",
    "    # Fazer previsões no conjunto de teste do fold atual\n",
    "    predictions_fold = tree_fold.predict(X_test_fold)\n",
    "    \n",
    "    # Calcular a acurácia para este fold\n",
    "    accuracy_fold = accuracy_score(y_test_fold, predictions_fold)\n",
    "    accuracies.append(accuracy_fold)\n",
    "\n",
    "# Calcular a acurácia média da validação cruzada\n",
    "mean_accuracy = np.mean(accuracies)\n",
    "print(\"Acurácia média da validação cruzada:\", mean_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef27d0a",
   "metadata": {},
   "source": [
    ">Essencialmente, esta implementação divide os dados em num_folds partes, treina o modelo em cada parte (fold) e avalia o desempenho do modelo em um conjunto de teste separado para cada fold. Finalmente, calcula a média das acurácias obtidas em cada fold para obter a acurácia média da validação cruzada."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb8acf3",
   "metadata": {},
   "source": [
    "`Prompt 6: preciso da implementção de um trecho de código que apresente as seguintes métricas:  matriz de confusão, acurácia, recall, precisão e f1-score`\n",
    ">Entendi, vamos implementar as métricas sem usar bibliotecas externas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "232cb231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusão:\n",
      "                  | Predito Positive | Predito Negative \n",
      "Actual Positive   |        13        |        0        \n",
      "Actual Negative   |        0         |        53        \n",
      "Acurácia: 1.0\n",
      "Precisão: 1.0\n",
      "Recall: 1.0\n",
      "F1-score: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Definir uma função para calcular a matriz de confusão\n",
    "def confusion_matrix_custom(y_true, y_pred):\n",
    "    true_positives = sum((true == 1 and pred == 1) for true, pred in zip(y_true, y_pred))\n",
    "    true_negatives = sum((true == 0 and pred == 0) for true, pred in zip(y_true, y_pred))\n",
    "    false_positives = sum((true == 0 and pred == 1) for true, pred in zip(y_true, y_pred))\n",
    "    false_negatives = sum((true == 1 and pred == 0) for true, pred in zip(y_true, y_pred))\n",
    "    return true_positives, true_negatives, false_positives, false_negatives\n",
    "\n",
    "# Calcular a matriz de confusão\n",
    "true_positives, true_negatives, false_positives, false_negatives = confusion_matrix_custom(y_test, predictions)\n",
    "print(\"Matriz de Confusão:\")\n",
    "print(\"                  | Predito Positive | Predito Negative \")\n",
    "print(\"Actual Positive   |        {}        |        {}        \".format(true_positives, false_negatives))\n",
    "print(\"Actual Negative   |        {}         |        {}        \".format(false_positives, true_negatives))\n",
    "\n",
    "# Calcular a acurácia\n",
    "accuracy = (true_positives + true_negatives) / len(y_test)\n",
    "print(\"Acurácia:\", accuracy)\n",
    "\n",
    "# Calcular a precisão\n",
    "precision = true_positives / (true_positives + false_positives)\n",
    "print(\"Precisão:\", precision)\n",
    "\n",
    "# Calcular o recall\n",
    "recall = true_positives / (true_positives + false_negatives)\n",
    "print(\"Recall:\", recall)\n",
    "\n",
    "# Calcular o F1-score\n",
    "f1 = 2 * (precision * recall) / (precision + recall)\n",
    "print(\"F1-score:\", f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0bfeb42-1db6-49a5-a7ee-6e0aedfaa61a",
   "metadata": {},
   "source": [
    "***\n",
    "## _Aplicando o Código_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f794b48b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia do modelo: 1.0\n",
      "Acurácia média da validação cruzada: 1.0\n",
      "Matriz de Confusão:\n",
      "                  | Predito Positive | Predito Negative \n",
      "Actual Positive   |        13        |        0        \n",
      "Actual Negative   |        0         |        53        \n",
      "Acurácia: 1.0\n",
      "Precisão: 1.0\n",
      "Recall: 1.0\n",
      "F1-score: 1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, feature_index=None, threshold=None, left=None, right=None, value=None):\n",
    "        self.feature_index = feature_index  # Índice do recurso usado para dividir os dados\n",
    "        self.threshold = threshold  # Valor de divisão\n",
    "        self.left = left  # Subárvore à esquerda\n",
    "        self.right = right  # Subárvore à direita\n",
    "        self.value = value  # Valor da classe para folhas (somente se for uma folha)\n",
    "\n",
    "class DecisionTreeClassifier:\n",
    "    def __init__(self, max_depth=None):\n",
    "        self.max_depth = max_depth\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.num_classes = len(set(y))\n",
    "        self.num_features = X.shape[1]\n",
    "        self.tree = self._grow_tree(X, y)\n",
    "\n",
    "    def _gini(self, y):\n",
    "        classes = set(y)\n",
    "        n_instances = len(y)\n",
    "        gini = 1.0\n",
    "        for cls in classes:\n",
    "            proportion = np.sum(y == cls) / n_instances\n",
    "            gini -= proportion ** 2\n",
    "        return gini\n",
    "\n",
    "    def _best_split(self, X, y):\n",
    "        best_gini = float('inf')\n",
    "        best_criteria = None  # Critérios para divisão: (feature_index, threshold)\n",
    "        \n",
    "        for feature_index in range(self.num_features):\n",
    "            thresholds = np.unique(X[:, feature_index])\n",
    "            for threshold in thresholds:\n",
    "                left_indices = np.where(X[:, feature_index] <= threshold)[0]\n",
    "                right_indices = np.where(X[:, feature_index] > threshold)[0]\n",
    "                \n",
    "                if len(left_indices) == 0 or len(right_indices) == 0:\n",
    "                    continue\n",
    "                \n",
    "                gini = self._gini_split(y[left_indices], y[right_indices])\n",
    "                \n",
    "                if gini < best_gini:\n",
    "                    best_gini = gini\n",
    "                    best_criteria = (feature_index, threshold)\n",
    "        \n",
    "        return best_criteria\n",
    "\n",
    "    def _gini_split(self, left_y, right_y):\n",
    "        p_left = len(left_y) / (len(left_y) + len(right_y))\n",
    "        gini_left = self._gini(left_y)\n",
    "        gini_right = self._gini(right_y)\n",
    "        gini = p_left * gini_left + (1 - p_left) * gini_right\n",
    "        return gini\n",
    "\n",
    "    def _grow_tree(self, X, y, depth=0):\n",
    "        num_samples_per_class = [np.sum(y == i) for i in range(self.num_classes)]\n",
    "        predicted_class = np.argmax(num_samples_per_class)\n",
    "        node = Node(value=predicted_class)\n",
    "        \n",
    "        if depth < self.max_depth:\n",
    "            criteria = self._best_split(X, y)\n",
    "            if criteria:\n",
    "                feature_index, threshold = criteria\n",
    "                left_indices = np.where(X[:, feature_index] <= threshold)[0]\n",
    "                right_indices = np.where(X[:, feature_index] > threshold)[0]\n",
    "                left_subtree = self._grow_tree(X[left_indices], y[left_indices], depth + 1)\n",
    "                right_subtree = self._grow_tree(X[right_indices], y[right_indices], depth + 1)\n",
    "                node = Node(feature_index=feature_index, threshold=threshold, left=left_subtree, right=right_subtree)\n",
    "        return node\n",
    "\n",
    "    def predict(self, X):\n",
    "        return [self._predict_tree(x, self.tree) for x in X]\n",
    "\n",
    "    def _predict_tree(self, x, tree):\n",
    "        if tree.value is not None:\n",
    "        # Se a árvore for uma folha, retornar o valor booleano correspondente\n",
    "            return bool(tree.value)\n",
    "        if x[tree.feature_index] <= tree.threshold:\n",
    "            return self._predict_tree(x, tree.left)\n",
    "        else:\n",
    "            return self._predict_tree(x, tree.right)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Carregar o conjunto de dados penguins\n",
    "penguins_data = pd.read_csv(\"https://raw.githubusercontent.com/dataprofessor/data/master/penguins_cleaned.csv\")\n",
    "\n",
    "# Remover linhas com valores nulos\n",
    "penguins_data.dropna(inplace=True)\n",
    "\n",
    "# Converter variáveis categóricas em numéricas usando one-hot encoding manualmente\n",
    "penguins_data = pd.concat([penguins_data, pd.get_dummies(penguins_data['species'], prefix='species')], axis=1)\n",
    "penguins_data = pd.concat([penguins_data, pd.get_dummies(penguins_data['island'], prefix='island')], axis=1)\n",
    "penguins_data = pd.concat([penguins_data, pd.get_dummies(penguins_data['sex'], prefix='sex')], axis=1)\n",
    "\n",
    "# Remover as colunas originais categóricas\n",
    "penguins_data.drop(['species', 'island', 'sex'], axis=1, inplace=True)\n",
    "\n",
    "# Separar os dados em features (X) e target (y)\n",
    "X = penguins_data.drop('species_Chinstrap', axis=1).values\n",
    "y = penguins_data['species_Chinstrap'].values\n",
    "\n",
    "# Dividir os dados manualmente em conjunto de treinamento e conjunto de teste\n",
    "def manual_train_test_split(X, y, test_size=0.2, random_state=None):\n",
    "    if random_state:\n",
    "        np.random.seed(random_state)\n",
    "        \n",
    "    num_samples = len(X)\n",
    "    indices = np.random.permutation(num_samples)\n",
    "    test_size = int(test_size * num_samples)\n",
    "    \n",
    "    X_train = X[indices[:-test_size]]\n",
    "    X_test = X[indices[-test_size:]]\n",
    "    y_train = y[indices[:-test_size]]\n",
    "    y_test = y[indices[-test_size:]]\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "X_train, X_test, y_train, y_test = manual_train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "def accuracy_score(y_true, y_pred):\n",
    "    correct = 0\n",
    "    total = len(y_true)\n",
    "    for true_label, pred_label in zip(y_true, y_pred):\n",
    "        if true_label == pred_label:\n",
    "            correct += 1\n",
    "    return correct / total\n",
    "# Criar uma instância do DecisionTreeClassifier com max_depth definido\n",
    "tree_classifier = DecisionTreeClassifier(max_depth=3)\n",
    "\n",
    "# Treinar o modelo com os dados de treinamento\n",
    "tree_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Fazer previsões nos dados de teste\n",
    "predictions = tree_classifier.predict(X_test)\n",
    "\n",
    "# Calcular a acurácia usando a função accuracy_score\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Acurácia do modelo:\", accuracy)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Definir uma função para dividir os dados em K folds\n",
    "def k_fold_split(X, y, num_folds=5, random_state=None):\n",
    "    if random_state:\n",
    "        np.random.seed(random_state)\n",
    "    \n",
    "    num_samples = len(X)\n",
    "    fold_size = num_samples // num_folds\n",
    "    indices = np.random.permutation(num_samples)\n",
    "    \n",
    "    for i in range(num_folds):\n",
    "        start = i * fold_size\n",
    "        end = (i + 1) * fold_size if i < num_folds - 1 else num_samples\n",
    "        \n",
    "        test_indices = indices[start:end]\n",
    "        train_indices = np.concatenate((indices[:start], indices[end:]))\n",
    "        \n",
    "        yield X[train_indices], X[test_indices], y[train_indices], y[test_indices]\n",
    "\n",
    "# Definir uma função para calcular a acurácia\n",
    "def accuracy_score(y_true, y_pred):\n",
    "    correct = np.sum(y_true == y_pred)\n",
    "    total = len(y_true)\n",
    "    return correct / total\n",
    "\n",
    "# Realizar validação cruzada\n",
    "num_folds = 5\n",
    "accuracies = []\n",
    "\n",
    "for X_train_fold, X_test_fold, y_train_fold, y_test_fold in k_fold_split(X_train, y_train, num_folds=num_folds, random_state=42):\n",
    "    # Treinar o modelo em um fold\n",
    "    tree_fold = DecisionTreeClassifier(max_depth=3)\n",
    "    tree_fold.fit(X_train_fold, y_train_fold)\n",
    "    \n",
    "    # Fazer previsões no conjunto de teste do fold atual\n",
    "    predictions_fold = tree_fold.predict(X_test_fold)\n",
    "    \n",
    "    # Calcular a acurácia para este fold\n",
    "    accuracy_fold = accuracy_score(y_test_fold, predictions_fold)\n",
    "    accuracies.append(accuracy_fold)\n",
    "\n",
    "# Calcular a acurácia média da validação cruzada\n",
    "mean_accuracy = np.mean(accuracies)\n",
    "print(\"Acurácia média da validação cruzada:\", mean_accuracy)\n",
    "\n",
    "# Definir uma função para calcular a matriz de confusão\n",
    "def confusion_matrix_custom(y_true, y_pred):\n",
    "    true_positives = sum((true == 1 and pred == 1) for true, pred in zip(y_true, y_pred))\n",
    "    true_negatives = sum((true == 0 and pred == 0) for true, pred in zip(y_true, y_pred))\n",
    "    false_positives = sum((true == 0 and pred == 1) for true, pred in zip(y_true, y_pred))\n",
    "    false_negatives = sum((true == 1 and pred == 0) for true, pred in zip(y_true, y_pred))\n",
    "    return true_positives, true_negatives, false_positives, false_negatives\n",
    "\n",
    "# Calcular a matriz de confusão\n",
    "true_positives, true_negatives, false_positives, false_negatives = confusion_matrix_custom(y_test, predictions)\n",
    "print(\"Matriz de Confusão:\")\n",
    "print(\"                  | Predito Positive | Predito Negative \")\n",
    "print(\"Actual Positive   |        {}        |        {}        \".format(true_positives, false_negatives))\n",
    "print(\"Actual Negative   |        {}         |        {}        \".format(false_positives, true_negatives))\n",
    "\n",
    "# Calcular a acurácia\n",
    "accuracy = (true_positives + true_negatives) / len(y_test)\n",
    "print(\"Acurácia:\", accuracy)\n",
    "\n",
    "# Calcular a precisão\n",
    "precision = true_positives / (true_positives + false_positives)\n",
    "print(\"Precisão:\", precision)\n",
    "\n",
    "# Calcular o recall\n",
    "recall = true_positives / (true_positives + false_negatives)\n",
    "print(\"Recall:\", recall)\n",
    "\n",
    "# Calcular o F1-score\n",
    "f1 = 2 * (precision * recall) / (precision + recall)\n",
    "print(\"F1-score:\", f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0f7e17-ec56-456e-8944-6ac8827ea44f",
   "metadata": {},
   "source": [
    "***\n",
    "## _Análise e Considerações_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aaaa8ca",
   "metadata": {},
   "source": [
    "### __Ponto Fortes__\n",
    "\n",
    "* __Implementação sem o uso de bibliotecas externas__\n",
    "\n",
    "O desenvolvimento do código realizado pelo ChatGPT implementa o modelo Árvores de Decisão do zero, sem o uso de bibliotecas externas, como o \"scikit-learn\"\n",
    "\n",
    "* __Cálculo das Métricas__\n",
    "\n",
    "Além do desenvolvimento do modelo, os cálculos das métricas para o modelo também foram desenvolvidas sem a utilização de bibliotecas externas.\n",
    "\n",
    "* __Preparação de dados__\n",
    "\n",
    "A remoção de linhas com valores em branco foi realizada no início do processo para garantir que não afetasse o desempenho do algoritmo.\n",
    "\n",
    "* __Utilização do Índice Gini__\n",
    "\n",
    "O Índice Gini foi utilizado no algoritmo para verificar a pureza dos nodos.\n",
    "\n",
    "* __Correção de erros__\n",
    "\n",
    "No momento em que percebe-se que os resultados das métricas estavam sendo igual a 1, foi descoberto que os dados de rótulos e precisões estavam em diferentes formatos e então isso foi corrigido.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9282a0f",
   "metadata": {},
   "source": [
    "### __Potenciais Problemas e Sugestões de Melhoria__\n",
    "\n",
    "* __Eficiência computacional__\n",
    "\n",
    "A implementação de algumas funções utilizam loop duplo para percorrer os valores, o que torna computacionalmente caro para maiores conjuntos.\n",
    "\n",
    "* __Erros relacionados à acurácia__\n",
    "\n",
    "Por mais que tenha sido descoberto que os formatos dos rótulos e previsões estavam diferentes, a padronização não foi o suficiente para que a acurácia saísse de 1.\n",
    "\n",
    "* __Validação cruzada__\n",
    "\n",
    "Quando o modelo apresentou uma acurácia de 1, foi decidido que seria uma boa opção usar a validação cruzada para tentar corrigir esse valor. No entanto, mesmo após a aplicação da validação cruzada, o valor da acurácia permaneceu em 1. Isso pode indicar um problema mais profundo com o modelo, como overfitting, onde o modelo se ajusta perfeitamente aos dados de treinamento, mas não generaliza bem para novos dados.\n",
    "\n",
    "* __Possível overfitting__\n",
    "\n",
    "Ao calcular as métricas, notou-se que não foram encontrados falsos positivos nem falsos negativos, o que significa que o modelo classificou corretamente todos os exemplos de teste. Essa alta precisão pode indicar um fenômeno conhecido como overfitting, no qual o modelo Árvores de decisão é propenso.\n",
    "\n",
    "* __Poda__\n",
    "\n",
    "O algoritmo desenvolvido não utilizou a poda, porém essa abordagem poderia remover o possível fenômeno de overfitting do modelo.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01aea34",
   "metadata": {},
   "source": [
    "***\n",
    "### __Conclusão__\n",
    "\n",
    "\n",
    "Apesar dos esforços em implementar uma Árvore de Decisão do zero e garantir que as métricas fossem calculadas corretamente, o modelo apresentou uma acurácia de 1 e não foi possível resolver esse problema mesmo após a aplicação da validação cruzada. Isso sugere a presença de overfitting, onde o modelo se ajustou excessivamente aos dados de treinamento e falhou em generalizar para novos dados.\n",
    "\n",
    "Uma possível solução para mitigar o overfitting seria a utilização da técnica de poda, que consiste em remover partes da árvore que não contribuem significativamente para melhorar o desempenho do modelo. Além disso, poderiam ser exploradas outras técnicas de regularização para evitar o overfitting, como a limitação da profundidade da árvore ou o uso de um número mínimo de amostras por folha.\n",
    "\n",
    "Em resumo, embora a implementação inicial tenha sido bem-sucedida em criar uma Árvore de Decisão sem o uso de bibliotecas externas e calcular as métricas com precisão, ainda há espaço para melhorias, especialmente no que diz respeito à capacidade do modelo de generalizar para novos dados. A aplicação de técnicas como a poda podem ajudar a resolver esse problema e melhorar o desempenho geral do modelo."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
