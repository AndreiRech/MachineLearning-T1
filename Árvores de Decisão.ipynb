{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce81486c-2b33-4624-a801-494814266106",
   "metadata": {},
   "source": [
    "# __ÁRVORES DE DECISÃO__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0bada04-0580-4174-9fb3-37fa1a4721b5",
   "metadata": {},
   "source": [
    "***\n",
    "## _Prompts e Respostas_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5f7bbf",
   "metadata": {},
   "source": [
    "` Prompt 1: Necessito que crie um algoritmo sem o uso de bibliotecas como o 'scikit-learn' para o método de aprendizado supervisionado Árvores de Decisão que lide com valores numéricos e categóricos na linguagem Python (Jupyter Notebook)`\n",
    "\n",
    ">Claro, vou te orientar sobre como criar um algoritmo para Árvores de Decisão em Python sem usar bibliotecas como scikit-learn. Vamos começar definindo a estrutura básica de uma árvore de decisão e, em seguida, discutiremos como construir o algoritmo passo a passo.\n",
    "\n",
    ">Uma árvore de decisão é uma estrutura hierárquica composta por nós de decisão e nós de folha. Em cada nó de decisão, uma pergunta é feita sobre um atributo do conjunto de dados e, dependendo da resposta, o fluxo segue por diferentes ramos da árvore. Nos nós de folha, uma decisão é tomada.\n",
    "\n",
    ">Vamos criar um algoritmo simples para Árvores de Decisão:\n",
    "\n",
    ">Divisão de Dados: Começamos dividindo nossos dados em conjuntos de treinamento e teste.\n",
    ">Definição da Estrutura da Árvore: Definimos a estrutura da árvore, criando classes para nós de decisão e nós de folha.\n",
    ">Cálculo da Impureza: Implementamos funções para calcular a impureza dos dados, como o índice de Gini ou a entropia.\n",
    ">Criação da Árvore: Implementamos a lógica para construir a árvore de decisão recursivamente, dividindo os dados com base nos atributos e valores que maximizam a pureza.\n",
    ">Predição: Implementamos a função para prever os rótulos das amostras de teste usando a árvore treinada.\n",
    ">Vou começar criando a estrutura básica do código. Depois, podemos continuar com cada passo. Vamos lá:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc305d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, feature_index=None, threshold=None, left=None, right=None, value=None):\n",
    "        self.feature_index = feature_index  # Índice do atributo usado para a divisão\n",
    "        self.threshold = threshold  # Valor de corte para a divisão\n",
    "        self.left = left  # Subárvore esquerda\n",
    "        self.right = right  # Subárvore direita\n",
    "        self.value = value  # Valor da classe se o nó é uma folha\n",
    "\n",
    "class DecisionTree:\n",
    "    def __init__(self, max_depth=None):\n",
    "        self.max_depth = max_depth\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.n_classes = len(np.unique(y))\n",
    "        self.n_features = X.shape[1]\n",
    "        self.tree = self._grow_tree(X, y)\n",
    "\n",
    "    def _grow_tree(self, X, y, depth=0):\n",
    "        n_samples, n_features = X.shape\n",
    "        n_labels = len(np.unique(y))\n",
    "\n",
    "        # Critérios de parada para a recursão\n",
    "        if (self.max_depth is not None and depth >= self.max_depth) or n_labels == 1:\n",
    "            leaf_value = self._most_common_label(y)\n",
    "            return Node(value=leaf_value)\n",
    "\n",
    "        # Encontrar a melhor divisão\n",
    "        best_feat, best_thresh = self._best_criteria(X, y, n_samples, n_features)\n",
    "\n",
    "        # Dividir os dados e crescer recursivamente\n",
    "        left_indices, right_indices = self._split(X[:, best_feat], best_thresh)\n",
    "        left = self._grow_tree(X[left_indices, :], y[left_indices], depth + 1)\n",
    "        right = self._grow_tree(X[right_indices, :], y[right_indices], depth + 1)\n",
    "        return Node(feature_index=best_feat, threshold=best_thresh, left=left, right=right)\n",
    "\n",
    "    def _best_criteria(self, X, y, n_samples, n_features):\n",
    "        best_gini = np.inf\n",
    "        best_feat = None\n",
    "        best_thresh = None\n",
    "\n",
    "        for feat_index in range(n_features):\n",
    "            thresholds = np.unique(X[:, feat_index])\n",
    "            for threshold in thresholds:\n",
    "                left_indices, right_indices = self._split(X[:, feat_index], threshold)\n",
    "                if len(left_indices) == 0 or len(right_indices) == 0:\n",
    "                    continue\n",
    "                gini = self._gini_impurity(y[left_indices], y[right_indices])\n",
    "                if gini < best_gini:\n",
    "                    best_gini = gini\n",
    "                    best_feat = feat_index\n",
    "                    best_thresh = threshold\n",
    "        return best_feat, best_thresh\n",
    "\n",
    "    def _gini_impurity(self, left_labels, right_labels):\n",
    "        p_left = len(left_labels) / (len(left_labels) + len(right_labels))\n",
    "        p_right = len(right_labels) / (len(left_labels) + len(right_labels))\n",
    "        gini = 1.0 - (p_left**2 + p_right**2)\n",
    "        return gini\n",
    "\n",
    "    def _split(self, feature, threshold):\n",
    "        left_indices = np.where(feature <= threshold)[0]\n",
    "        right_indices = np.where(feature > threshold)[0]\n",
    "        return left_indices, right_indices\n",
    "\n",
    "    def _most_common_label(self, y):\n",
    "        return np.bincount(y).argmax()\n",
    "\n",
    "    def predict(self, X):\n",
    "        return [self._traverse_tree(x, self.tree) for x in X]\n",
    "\n",
    "    def _traverse_tree(self, x, node):\n",
    "        if node.value is not None:\n",
    "            return node.value\n",
    "        feature_value = x[node.feature_index]\n",
    "        if feature_value <= node.threshold:\n",
    "            return self._traverse_tree(x, node.left)\n",
    "        else:\n",
    "            return self._traverse_tree(x, node.right)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Esse é um começo para o algoritmo de Árvores de Decisão. Precisamos ainda testar e validar o código, além de implementar funções para calcular métricas de desempenho, como precisão, recall e F1-score. Vamos continuar a partir daqui!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2809108",
   "metadata": {},
   "source": [
    "`Prompt 2: Como processo  os dados do dataset \"penguins\" para utilizar neste algoritmo sem utilizar bibliotecas como sklearn? `\n",
    ">Para processar os dados do conjunto de dados penguins sem utilizar bibliotecas como Scikit-learn, você precisará carregar os dados e convertê-los para um formato compatível com o seu algoritmo de árvore de decisão. Aqui está um exemplo de como você pode fazer isso:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5c5dadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Carregar os dados dos pinguins\n",
    "penguins_data = pd.read_csv('penguins.csv')\n",
    "\n",
    "# Pré-processamento dos dados\n",
    "# Remover linhas com valores ausentes\n",
    "penguins_data.dropna(inplace=True)\n",
    "\n",
    "# Mapear as espécies para valores numéricos\n",
    "species_mapping = {'Adelie': 0, 'Chinstrap': 1, 'Gentoo': 2}\n",
    "penguins_data['species'] = penguins_data['species'].map(species_mapping)\n",
    "\n",
    "# Selecionar as características (atributos) e as classes (rótulos)\n",
    "X = penguins_data[['bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g']].values\n",
    "y = penguins_data['species'].values\n",
    "\n",
    "# Agora você pode usar X e y como entrada para o seu algoritmo de árvore de decisão\n",
    "# Certifique-se de que o algoritmo aceita arrays NumPy como entrada.\n",
    "# Por exemplo, você pode usar algo assim:\n",
    "decision_tree = DecisionTree(max_depth=3)\n",
    "decision_tree.fit(X, y)\n",
    "redictions = decision_tree.predict(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634a8ea6",
   "metadata": {},
   "source": [
    ">Este código carrega os dados do arquivo CSV \"penguins.csv\", remove as linhas com valores ausentes, mapeia as espécies para valores numéricos, seleciona as características e as classes e as converte em arrays NumPy para uso com o seu algoritmo de árvore de decisão. Certifique-se de substituir 'penguins.csv' pelo caminho do seu arquivo de dados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3a700b",
   "metadata": {},
   "source": [
    "` Prompt 3: como posso utilizar o dataset Penguins, sem o uso de bibliotecas como 'scikit-learn' para testar e treinar esse conjunto?`\n",
    "\n",
    ">Você pode treinar e testar um modelo usando o conjunto de dados \"Penguins\" sem o uso de bibliotecas como scikit-learn escrevendo seu próprio código para isso. Aqui está uma abordagem simples usando uma divisão de treinamento/teste e um modelo de árvore de decisão que você já possui:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "408ae7f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia do modelo: 0.45454545454545453\n"
     ]
    }
   ],
   "source": [
    "# Dividir os dados em conjuntos de treinamento e teste\n",
    "def train_test_split(X, y, test_size=0.2, random_state=None):\n",
    "    if random_state is not None:\n",
    "        np.random.seed(random_state)\n",
    "    n_samples = X.shape[0]\n",
    "    n_test = int(test_size * n_samples)\n",
    "    test_indices = np.random.choice(n_samples, n_test, replace=False)\n",
    "    train_indices = np.delete(np.arange(n_samples), test_indices)\n",
    "    X_train, X_test = X[train_indices], X[test_indices]\n",
    "    y_train, y_test = y[train_indices], y[test_indices]\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Treinar o modelo de árvore de decisão\n",
    "decision_tree = DecisionTree(max_depth=6)\n",
    "decision_tree.fit(X_train, y_train)\n",
    "\n",
    "# Testar o modelo\n",
    "predictions = decision_tree.predict(X_test)\n",
    "\n",
    "# Avaliar o desempenho do modelo (por exemplo, acurácia)\n",
    "accuracy = np.mean(predictions == y_test)\n",
    "print(\"Acurácia do modelo:\", accuracy) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f2b80a",
   "metadata": {},
   "source": [
    ">Este código divide os dados em conjuntos de treinamento e teste, treina um modelo de árvore de decisão com base nos dados de treinamento e testa o modelo com os dados de teste. Finalmente, ele calcula e imprime a acurácia do modelo. Certifique-se de substituir 'penguins.csv' pelo caminho do seu arquivo de dados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c8db3c",
   "metadata": {},
   "source": [
    "`Prompt 3: Preciso dos resultados de matriz de confusão, acurácia, recall, precisão e f1-score deste algoritmo`\n",
    "\n",
    ">Para calcular a matriz de confusão, acurácia, recall, precisão e F1-score, você pode usar funções disponíveis em bibliotecas como Scikit-learn ou implementá-las manualmente. Aqui está um exemplo de como você pode calcular essas métricas manualmente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1982016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusão:\n",
      "[[30  0  0]\n",
      " [13  0  0]\n",
      " [23  0  0]]\n",
      "Acurácia: 0.45454545454545453\n",
      "Recall: 0.3333333333333333\n",
      "Precisão: nan\n",
      "F1-score: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eduar\\AppData\\Local\\Temp\\ipykernel_19024\\2494088576.py:30: RuntimeWarning: invalid value encountered in divide\n",
      "  precision_per_class = np.diag(conf_matrix) / np.sum(conf_matrix, axis=0)\n"
     ]
    }
   ],
   "source": [
    "# Calcular a matriz de confusão\n",
    "def confusion_matrix(y_true, y_pred):\n",
    "    num_classes = len(np.unique(y_true))\n",
    "    conf_matrix = np.zeros((num_classes, num_classes), dtype=int)\n",
    "    for true, pred in zip(y_true, y_pred):\n",
    "        conf_matrix[true, pred] += 1\n",
    "    return conf_matrix\n",
    "\n",
    "# Calcular a acurácia\n",
    "def accuracy_score(y_true, y_pred):\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    correct_predictions = np.diag(conf_matrix).sum()\n",
    "    total_predictions = conf_matrix.sum()\n",
    "    accuracy = correct_predictions / total_predictions\n",
    "    return accuracy\n",
    "\n",
    "# Calcular o recall\n",
    "def recall_score(y_true, y_pred, average='macro'):\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    recall_per_class = np.diag(conf_matrix) / np.sum(conf_matrix, axis=1)\n",
    "    if average == 'macro':\n",
    "        recall = np.mean(recall_per_class)\n",
    "    elif average == 'micro':\n",
    "        recall = np.sum(np.diag(conf_matrix)) / np.sum(conf_matrix)\n",
    "    return recall\n",
    "\n",
    "# Calcular a precisão\n",
    "def precision_score(y_true, y_pred, average='macro'):\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    precision_per_class = np.diag(conf_matrix) / np.sum(conf_matrix, axis=0)\n",
    "    if average == 'macro':\n",
    "        precision = np.mean(precision_per_class)\n",
    "    elif average == 'micro':\n",
    "        precision = np.sum(np.diag(conf_matrix)) / np.sum(conf_matrix)\n",
    "    return precision\n",
    "\n",
    "# Calcular o F1-score\n",
    "def f1_score(y_true, y_pred, average='macro'):\n",
    "    precision = precision_score(y_true, y_pred, average)\n",
    "    recall = recall_score(y_true, y_pred, average)\n",
    "    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "    return f1\n",
    "\n",
    "# Fazer previsões usando o modelo de árvore de decisão\n",
    "predictions = decision_tree.predict(X_test)\n",
    "\n",
    "# Calcular as métricas\n",
    "conf_matrix = confusion_matrix(y_test, predictions)\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "recall = recall_score(y_test, predictions)\n",
    "precision = precision_score(y_test, predictions)\n",
    "f1 = f1_score(y_test, predictions)\n",
    "\n",
    "print(\"Matriz de Confusão:\")\n",
    "print(conf_matrix)\n",
    "print(\"Acurácia:\", accuracy)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"Precisão:\", precision)\n",
    "print(\"F1-score:\", f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0bfeb42-1db6-49a5-a7ee-6e0aedfaa61a",
   "metadata": {},
   "source": [
    "***\n",
    "## _Aplicando o Código_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0f7e17-ec56-456e-8944-6ac8827ea44f",
   "metadata": {},
   "source": [
    "***\n",
    "## _Análise e Considerações_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce113802-2897-4c5b-ba21-946a24a8f050",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
